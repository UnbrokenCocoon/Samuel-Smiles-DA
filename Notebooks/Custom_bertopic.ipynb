{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install umap hdbscan bertopic"
      ],
      "metadata": {
        "id": "vLxtdNOA3b3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "# Detect if running in Google Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base_dir = \"/content/drive/MyDrive/Smiles Discourse Analysis\"\n",
        "else:\n",
        "    base_dir = \"path/to/your/local/project/folder\" # add directory if running locally"
      ],
      "metadata": {
        "id": "eIviLpdqhPxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Define save directory\n",
        "pickle_dir = os.path.join(base_dir, \"pickles\")\n",
        "os.makedirs(pickle_dir, exist_ok=True)\n",
        "\n",
        "# open  pickles correctly\n",
        "with open(os.path.join(pickle_dir, 'self_help.pkl'), 'rb') as f:\n",
        "    self_help_sentences = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(pickle_dir, 'thrift.pkl'), 'rb') as f:\n",
        "    thrift_sentences = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(pickle_dir, 'self_help_embeddings.pkl'), 'rb') as f:\n",
        "    sh_embeddings = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(pickle_dir, 'thrift_embeddings.pkl'), 'rb') as f:\n",
        "    th_embeddings = pickle.load(f)"
      ],
      "metadata": {
        "id": "gHgkRx7d2F3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDu3TVDX1-XJ"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "from umap.umap_ import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# These are taken from the Bertopic docs as a way of fine tuning Bertopics\n",
        "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
        "\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=150, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
        "\n",
        "\n",
        "vectorizer_model = CountVectorizer(\n",
        "    stop_words=\"english\",\n",
        "    min_df=2,\n",
        "    ngram_range=(1, 2)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you are unsatisifed with your results change min cluster, n_neighbors, min_topic_size.\n",
        "# In basic terms you are looking to have as small a count in -1 as possible, with coherent topics, each with some consistency in size.\n",
        "# However, your goal will determine how you use Bertopic and it is recommended going for a closer looking into the docs for more detail.\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=25, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
        "UMAP(n_neighbors=10, min_dist=0.2, n_components=2, metric='cosine')\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "\n",
        "# This begins with self-help\n",
        "embeddings = np.array(sh_embeddings)\n",
        "embeddings = normalize(embeddings, norm='l2', axis=1)\n",
        "topic_model = BERTopic(\n",
        "    embedding_model=None,\n",
        "    umap_model=umap_model,\n",
        "    vectorizer_model=vectorizer_model,\n",
        "    hdbscan_model = hdbscan_model,\n",
        "    min_sample = 15,\n",
        "    min_topic_size=25,                  # increase to merge small/fuzzy clusters\n",
        "    nr_topics=45,                   # can also specify e.g. 50\n",
        "    top_n_words=10,                     # how many words shown per topic\n",
        "    verbose=True\n",
        ")\n",
        "topics, probs = topic_model.fit_transform(self_help_sentences, embeddings)"
      ],
      "metadata": {
        "id": "9mYQ2iWL8BXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Step 1: Get full topic metadata from BERTopic\n",
        "topic_info = topic_model.get_topic_info()\n",
        "\n",
        "# Step 2: Exclude outliers (Topic -1 is usually noise)\n",
        "topic_info_filtered = topic_info[topic_info[\"Topic\"] != -1]\n",
        "\n",
        "# Step 3: Get top 20 topics by frequency\n",
        "top_df = topic_info_filtered.nlargest(20, \"Count\").copy()\n",
        "print(topic_info)"
      ],
      "metadata": {
        "id": "_6W6JC4H5Dfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This provides a short overview of the topics in a way which can be quickly seen.\n",
        "# The goal of this graph is to help with understanding issues with the topics.\n",
        "# If you want to use this graph in your work, you will need to add custom topic names to it\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(top_df[\"Name\"], top_df[\"Count\"], color=\"darkgreen\")\n",
        "plt.xlabel(\"Sentence Count\")\n",
        "plt.title(\"Top BERTopic Clusters (Cleaned & Interpretable)\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P6cwqgep5pP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These graphs can also help to understand the topics more.\n",
        "# Look for internal consistency and overlapping terms\n",
        "topic_model.visualize_barchart(top_n_topics=20)"
      ],
      "metadata": {
        "id": "MgfFlgm8_iun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose a filename\n",
        "top_df.to_csv(os.path.join(save_path, \".csv\"))"
      ],
      "metadata": {
        "id": "Or535EqOL0LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "# This cell has no output. It prepare the variables for the next cell which then outputs the visual UMAP representation of the topic model\n",
        "# This is taken from the Bertopic documentation and ammended only slightly.\n",
        "\n",
        "topic_info_filtered = topic_info[topic_info[\"Topic\"] != -1]\n",
        "\n",
        "umap_model = UMAP(\n",
        "    n_neighbors=10,\n",
        "    n_components=2,\n",
        "    min_dist=0.2,  # Try 0.2–0.3 for clearer spread\n",
        "    metric='cosine',\n",
        "    random_state=42\n",
        ")\n",
        "reduced_embeddings_2d = umap_model.fit_transform(embeddings)\n",
        "\n",
        "\n",
        "# Step 3: Get top 20 topics by frequency\n",
        "top_df = topic_info_filtered.nlargest(20, \"Count\").copy()\n",
        "\n",
        "# Define colors for the visualization to iterate over\n",
        "colors = itertools.cycle(['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000'])\n",
        "top_topics = set(top_df[\"Topic\"].astype(str))\n",
        "color_key = {topic: next(colors) for topic in top_topics}\n",
        "\n",
        "doc_topics = [str(t) for t in topic_model.topics_]\n",
        "\n",
        "# Full UMAP plot dataframe, filtered to Top 20 topics\n",
        "df = pd.DataFrame({\n",
        "    \"x\": reduced_embeddings_2d[:, 0],\n",
        "    \"y\": reduced_embeddings_2d[:, 1],\n",
        "    \"Topic\": doc_topics,\n",
        "    \"Length\": [len(doc) for doc in all_sentences]\n",
        "})\n",
        "\n",
        "df = df[df[\"Topic\"].isin(top_topics)]\n",
        "df = df[(df.y > -10) & (df.y < 10) & (df.x > -10) & (df.x < 10)]\n",
        "df[\"Topic\"] = df[\"Topic\"].astype(\"category\")\n",
        "\n",
        "mean_df = df.groupby(\"Topic\").mean(numeric_only=True).reset_index()\n",
        "mean_df[\"Topic\"] = mean_df[\"Topic\"].astype(int)\n",
        "mean_df = mean_df.sort_values(\"Topic\")"
      ],
      "metadata": {
        "id": "mtSPrsfy6B3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This gives a rough look at the topic model to see whether there are any immediate errors.\n",
        "# If everything is looking acceptable, then it is time to label then create the legend\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Recalculate ranges and padding\n",
        "x_center = df[\"x\"].mean()\n",
        "y_center = df[\"y\"].mean()\n",
        "\n",
        "x_range = df[\"x\"].max() - df[\"x\"].min()\n",
        "y_range = df[\"y\"].max() - df[\"y\"].min()\n",
        "\n",
        "padding = 0.1  # 10% padding\n",
        "\n",
        "x_pad = x_range * padding\n",
        "y_pad = y_range * padding\n",
        "\n",
        "#plt.figure(figsize=(10, 8))\n",
        "\n",
        "sns.scatterplot(\n",
        "    data=df,\n",
        "    x=\"x\",\n",
        "    y=\"y\",\n",
        "    hue=\"Topic\",\n",
        "    palette=color_key,\n",
        "    s=10,\n",
        "    alpha=0.6,\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "# Recenter around midpoint\n",
        "plt.xlim(x_center - x_range / 2 - x_pad, x_center + x_range / 2 + x_pad)\n",
        "plt.ylim(y_center - y_range / 2 - y_pad, y_center + y_range / 2 + y_pad)\n",
        "\n",
        "plt.title(\"UMAP Projection of Top 20 Topics\", fontsize=16)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "\n",
        "#plt.savefig(\"umap_centered.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GQDbW3IjHkCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is an example list of custom topic labels. You will need to develop them by hand.\n",
        "# You can export top_df to a LLM then ask it to use that data to create the labels.\n",
        "custom_topic_labels = {\n",
        "    0: \"Unite Community\",\n",
        "    1: \"Climate and fuel issues\",\n",
        "    2: \"NHS, health and housing\",\n",
        "    3: \"Labour Party relations\",\n",
        "    4: \"Food banks\",\n",
        "    5: \"Local branch reports\",\n",
        "    6: \"Better buses campaign\",\n",
        "    7: \"Universal Credit and disability\",\n",
        "    8: \"Palestine and solidarity\",\n",
        "    9: \"Schools and education\",\n",
        "    10: \"Branch roles and meetings\",\n",
        "    11: \"Reports and dates\",\n",
        "    12: \"Branch motions\",\n",
        "    13: \"Stalls and outreach\",\n",
        "    14: \"Local events\",\n",
        "    15: \"Meetings and forthcoming events\",\n",
        "    16: \"Young members and social media\",\n",
        "    17: \"Campaigning\",\n",
        "    18: \"Education industrial issues\",\n",
        "    19: \"Far right resistance\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "ntKzDq1BPV8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph should be the final version with\n",
        "\n",
        "plt.figure(figsize=(18, 12))\n",
        "x_low, x_high = np.percentile(df[\"x\"], [0.5, 99.5])\n",
        "y_low, y_high = np.percentile(df[\"y\"], [0.5, 99.5])\n",
        "\n",
        "df_filtered = df[(df[\"x\"] > x_low) & (df[\"x\"] < x_high) & (df[\"y\"] > y_low) & (df[\"y\"] < y_high)]\n",
        "df_filtered = df.copy()\n",
        "\n",
        "sns.scatterplot(\n",
        "    data=df_filtered,\n",
        "    x=\"x\",\n",
        "    y=\"y\",\n",
        "    hue=\"Topic\",\n",
        "    palette=color_key,\n",
        "    s=60,           # ⬅️ BOLDER markers\n",
        "    alpha=0.7,\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "# Make sure to change the title when changing dataset\n",
        "plt.title(\"Top 20 Topics Self-Help\", fontsize=27)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Custom legend\n",
        "legend_handles = [\n",
        "    mpatches.Patch(color=color_key[str(i)], label=custom_topic_labels[i])\n",
        "    for i in sorted(custom_topic_labels.keys())\n",
        "]\n",
        "\n",
        "plt.legend(\n",
        "    handles=legend_handles,\n",
        "    loc=\"upper left\",\n",
        "    bbox_to_anchor=(0.97, 1),\n",
        "    borderaxespad=0.,\n",
        "    title=\"Topics\",\n",
        "    fontsize=25,\n",
        "    title_fontsize=27,\n",
        "    ncol=1,\n",
        "    frameon=True\n",
        ")\n",
        "\n",
        "# Export\n",
        "save_path = r'/content/drive/MyDrive/final exports' # choose a directory, such as this\n",
        "#plt.savefig(os.path.join(save_path,\"umap.png\"), dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RcbtFWbhQTuw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}