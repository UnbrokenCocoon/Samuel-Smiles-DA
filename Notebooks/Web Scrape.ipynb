{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPcI0uOE67Hrfrh4N5LwRwk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install requests beautifulsoup4 nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGlUejCAE4_l","executionInfo":{"status":"ok","timestamp":1745486073411,"user_tz":-60,"elapsed":3515,"user":{"displayName":"tom compton","userId":"11608738456980900557"}},"outputId":"91d463e4-0335-41eb-d814-0b11f6533f4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","import pickle\n","\n","# Detect if running in Google Colab\n","IN_COLAB = 'google.colab' in sys.modules\n","\n","if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    base_dir = \"/content/drive/MyDrive/Smiles Discourse Analysis\"\n","else:\n","    base_dir = \"path/to/your/local/project/folder\" # add directory if running locally"],"metadata":{"id":"nX0_KISCgxHL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The first step is to download two books by Samuel Smiles. These texts â€” Self-Help and Thrift â€” were written by the same author, as part of the same series, and on related themes. This makes them well-suited for comparison: we can expect both overlap and divergence in how key concepts are expressed.\n","\n","While these two books serve as a compelling case study, any pair of corpora could be used for this type of analysis. What's important is that the comparison is guided by a clear research question or interpretive goal â€” beyond simply identifying similar sentences."],"metadata":{"id":"fcXRDDRwFV3N"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xzWy4-395InD","executionInfo":{"status":"ok","timestamp":1745486118567,"user_tz":-60,"elapsed":883,"user":{"displayName":"tom compton","userId":"11608738456980900557"}},"outputId":"96098c96-15db-484f-92b7-7408d221a4aa"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Self-Help - Total sentences: 4485\n","Self-Help - Full text length: 818382\n","thrift - Total sentences: 5926\n","thrift - Full text length: 714525\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import nltk\n","nltk.download('punkt_tab')\n","from nltk.tokenize import sent_tokenize\n","\n","# This is a fairly standard BeautifulSoup pipeline and should work well on most plain text sources.\n","# When working with other websites, however, extra care may be needed to handle inconsistent formatting,\n","# especially with headers, footers, and licensing text.\n","# Fortunately, Gutenberg has already removed most of this boilerplate for us, so we can proceed with minimal cleanup.\n","\n","\n","def fetch_and_process_gutenberg_text(url):\n","    # Step 1: Fetch the text file\n","    response = requests.get(url)\n","    raw_text = response.text\n","\n","    # Step 2: Remove Gutenberg headers/footers\n","    start_marker = \"*** START OF\"\n","    end_marker = \"*** END OF\"\n","    start_idx = raw_text.find(start_marker)\n","    end_idx = raw_text.find(end_marker)\n","\n","    if start_idx != -1 and end_idx != -1:\n","        clean_text = raw_text[start_idx:end_idx]\n","    else:\n","        clean_text = raw_text  # fallback\n","\n","    # Optional: Clean line breaks and extra spaces\n","    clean_text = clean_text.replace('\\r\\n', ' ').replace('\\n', ' ')\n","    clean_text = ' '.join(clean_text.split())\n","\n","    # Step 3: Tokenise into sentences\n","    sentences = sent_tokenize(clean_text)\n","\n","    return sentences, clean_text\n","\n","# ðŸ“˜ Samuel Smiles: Self-Help\n","self_help_url = \"https://www.gutenberg.org/files/935/935-0.txt\"\n","self_help_sentences, self_help_fulltext = fetch_and_process_gutenberg_text(self_help_url)\n","\n","# ðŸ“— Samuel Smiles: Character\n","thrift_url = \"https://www.gutenberg.org/cache/epub/14418/pg14418.txt\"\n","thrift_sentences, thrift_fulltext = fetch_and_process_gutenberg_text(thrift_url)\n","\n","#  check each variable is populated. Note len for full text will not give word length, but just show comparable variable sizes\n","print(f\"Self-Help - Total sentences: {len(self_help_sentences)}\")\n","print(f\"Self-Help - Full text length: {len(self_help_fulltext)}\")\n","print(f\"Thrift - Total sentences: {len(thrift_sentences)}\")\n","print(f\"Thrift - Full text length: {len(thrift_fulltext)}\")\n"]},{"cell_type":"code","source":["# Define save directory\n","pickle_dir = os.path.join(base_dir, \"pickles\")\n","os.makedirs(pickle_dir, exist_ok=True)\n","\n","# Save pickles correctly\n","with open(os.path.join(pickle_dir, 'self_help.pkl'), 'wb') as f:\n","    pickle.dump(self_help_sentences, f)\n","\n","with open(os.path.join(pickle_dir, 'thrift.pkl'), 'wb') as f:\n","    pickle.dump(thrift_sentences, f)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yl8bmBuhDKmn","executionInfo":{"status":"ok","timestamp":1745486124427,"user_tz":-60,"elapsed":2230,"user":{"displayName":"tom compton","userId":"11608738456980900557"}},"outputId":"78472c8a-536a-4844-a53b-217908589950"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]}]}